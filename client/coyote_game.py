import pyspiel
import numpy as np
from open_spiel.python.algorithms import external_sampling_mccfr
from open_spiel.python.algorithms import get_all_states
from open_spiel.python.algorithms import deep_cfr
import random
import pickle
import time
import tensorflow
import os
import tqdm
import matplotlib.pyplot as plt
import numpy as np
from pyspiel import PlayerId

import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()  # TF1äº’æ›ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ


_NUM_PLAYERS = 6  # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°
_NUM_DECLARATIONS = 121  # å®£è¨€ã®æœ€å¤§å€¤

_GAME_TYPE = pyspiel.GameType(
    short_name="python_coyote",
    long_name="Python Coyote",
    dynamics=pyspiel.GameType.Dynamics.SEQUENTIAL,
    chance_mode=pyspiel.GameType.ChanceMode.EXPLICIT_STOCHASTIC,
    information=pyspiel.GameType.Information.IMPERFECT_INFORMATION,
    utility=pyspiel.GameType.Utility.ZERO_SUM,
    reward_model=pyspiel.GameType.RewardModel.TERMINAL,
    max_num_players=6,
    min_num_players=2,
    provides_information_state_string=True,
    provides_information_state_tensor=True,
    provides_observation_string=True,
    provides_observation_tensor=False,
    parameter_specification={},  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã ãŒæ˜ç¤º
    default_loadable=False,      # è‡ªä½œPythonã‚²ãƒ¼ãƒ ã¯Falseã«ã—ã¦ãŠãã¨å®‰å¿ƒ
    provides_factored_observation_string=False
)

_GAME_INFO = pyspiel.GameInfo(
    num_distinct_actions=2,  # å®£è¨€ + ãƒãƒ£ãƒ¬ãƒ³ã‚¸
    max_chance_outcomes=15,  # å±±æœ­ã®ã‚«ãƒ¼ãƒ‰ã®ç¨®é¡æ•°
    num_players=_NUM_PLAYERS,
    min_utility=-1.0,
    max_utility=1.0,
    utility_sum=0.0,
    max_game_length=100,
)

class Deck:
    def __init__(self):
        #åˆæœŸæ¡ä»¶
        #?â†’ maxâ†’0â†’Ã—2:103,102,101,100ã«å¯¾å¿œ
        self.cards = [-10, -5, -5, 0, 0, 0,
                      1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3,
                      4, 4, 4, 4, 5, 5, 5, 5, 
                      10, 10, 10, 15, 15, 20, 
                      100, 101, 102, 103]
        
        self.cashed_cards = [] #å±±æœ­ã«æˆ»ã™ã‚«ãƒ¼ãƒ‰ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
    
    def shuffle(self):
        # print ("Deck shuffled.")
        random.shuffle(self.cards)
    
    def draw(self):
        if len(self.cards) > 0:
            return random.choice(self.cards) #ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚«ãƒ¼ãƒ‰ã‚’å¼•ã
        else:
            # print("No card left in the deck.")
            random.shuffle(self.cashed_cards) #å±±æœ­ã«æˆ»ã™ã‚«ãƒ¼ãƒ‰ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã™ã‚‹
            #å±±æœ­ãŒç©ºã«ãªã£ãŸã‚‰ã€æ¨ã¦æœ­ã‚’å±±æœ­ã«è¿½åŠ ã™ã‚‹
            self.reset()
            return random.choice(self.cards) #ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚«ãƒ¼ãƒ‰ã‚’å¼•ã
    
    def top_show_card(self):
        if len(self.cards) > 0:
            return self.cards[-1]
        return None
    
    def reset(self):
        self.cards = [-10, -5, -5, 0, 0, 0,
                      1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3,
                      4, 4, 4, 4, 5, 5, 5, 5, 
                      10, 10, 10, 15, 15, 20, 
                      100, 101, 102, 103]
        self.shuffle()             

class CoyoteState(pyspiel.State):
    def __init__(self, game):
        super().__init__(game)
        self._cur_player = 0
        self._is_terminal = False
        self._player_lives = [1] * _NUM_PLAYERS
        self._player_active = [True] * _NUM_PLAYERS
        self.current_declaration = 0
        self.last_declarer = _NUM_PLAYERS - 1
        self._calc_continue = False
        self.question_index = None
        rnd = random.Random(time.time_ns())
        self.deck = Deck() # ä½¿ç”¨ãƒ‡ãƒƒã‚­
        self.deck.shuffle() # ãƒ‡ãƒƒã‚­ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«
        self._cards = [None] * _NUM_PLAYERS  # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æ‰‹æœ­
        self.is_double_card = False
        self.is_shuffle_card = False
        self._expecting_draw = True  # ãƒãƒ£ãƒ³ã‚¹ãƒãƒ¼ãƒ‰ã«ç§»è¡Œã™ã‚‹ã‹ã©ã†ã‹
        self._used_cards = []  # ä½¿ç”¨æ¸ˆã¿ã‚«ãƒ¼ãƒ‰
        self._all_cards = [-10, -5, -5, 0, 0, 0,
                      1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3,
                      4, 4, 4, 4, 5, 5, 5, 5, 
                      10, 10, 10, 15, 15, 20, 
                      100, 101, 102, 103]
        # print("Game started!")

    def current_player(self):
        if self._is_terminal:
            return PlayerId.TERMINAL
        if self._expecting_draw:
            return PlayerId.CHANCE   # â† ãƒãƒ£ãƒ³ã‚¹ãƒãƒ¼ãƒ‰ã«ç§»è¡Œ
        return self._cur_player       # â† ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒãƒ¼ãƒ‰
                    
    def convert_card(self, cards, Is_othersum, deck):
            # print (f"cards: {cards}")
            true_cards = sorted(cards, reverse = True) 
            index = 0 
            # print(f"Initial true_cards: {true_cards}")
            while index < len(true_cards):
                card = true_cards[index]
                # print(f"Card drawn: {card}")

                #?ã‚’å¼•ã„ãŸã‚‰æ¬¡ã®ã‚«ãƒ¼ãƒ‰ã‚’å¼•ãã€å‡ºãŸç•ªå·ã®ã‚«ãƒ¼ãƒ‰ã¨äº¤æ›ã™ã‚‹
                #å…¨ä½“ã®æ•°ã®è¨ˆç®—ã¯ãƒ©ã‚¦ãƒ³ãƒ‰ã«ã¤ãä¸€å›

                #maxã‚’å¼•ã„ãŸã‚‰ã€æœ€ã‚‚å¤§ãã„ã‚«ãƒ¼ãƒ‰ã‚’0ã«ã™ã‚‹      
                if(card == 102):
                    normal_cards = [c for c in true_cards if c < 100] #é€šå¸¸ã‚«ãƒ¼ãƒ‰ã‚’å–å¾—
                    if len(normal_cards) != 0:
                        max_card = max(c for c in true_cards if c < 100) #æœ€å¤§å€¤ã‚’å–å¾—
                        max_index = true_cards.index(max_card) #æœ€å¤§å€¤ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
                        true_cards[max_index] = 0 #æœ€å¤§å€¤ã‚’0ã«ã™ã‚‹
                    true_cards[true_cards.index(102)] = 0    
                    
                #0(é»’èƒŒæ™¯)ã‚’å¼•ã„ãŸã‚‰ã€ãƒ©ã‚¦ãƒ³ãƒ‰çµ‚äº†å¾Œå±±æœ­ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹        
                elif(card == 101):
                    true_cards[index] = 0
                    #true_cards = sorted(( card for card in true_cards),reverse=True)
                    self.is_shuffle_card = True
                elif(card == 100):
                    true_cards[index] = 0
                    #true_cards = sorted(( card for card in true_cards),reverse=True)
                    self.is_double_card = True
                
                index += 1      
        
            return self.calc_card_sum(true_cards)   #é–¢æ•°ã®å¤–ã«åˆè¨ˆå€¤ã‚’è¿”ã™               

    def set_initial_state(self, player_num, current_declaration, used_cards, other_cards):
        self._player_lives = [0] * _NUM_PLAYERS
        self._player_active = [False] * _NUM_PLAYERS
        for i in range(player_num):
            self._player_lives[i] = 1
            self._player_active[i] = True
        self.current_declaration = current_declaration
        self.last_declarer = player_num - 1
        self._used_cards = used_cards
        print(other_cards)
        for i in range(_NUM_PLAYERS):
            if i == 0:
                self._cards[i] = "error"
            elif i < player_num:
                self._cards[i] = other_cards[i-1]
            else:
                self._cards[i] = 0
        self._expecting_draw = False  # ãƒãƒ£ãƒ³ã‚¹ãƒãƒ¼ãƒ‰ã«ç§»è¡Œã™ã‚‹ã‹ã©ã†ã‹

    def calc_card_sum(self, cards):
        card_sum = 0 #åˆæœŸåŒ–
        for card in cards:
            card_sum += card
        if(self.is_double_card):
            card_sum *= 2 
            self.is_double_card = False
        # print(f"gamesum is {card_sum}")    
        return card_sum    

    def _legal_actions(self, player):
        # if not self._player_active[player]:
        #     return []
        # if self.last_declarer is None: 
        #     return [0]  # æœ€åˆã®ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯å®£è¨€ã®ã¿
        # if self.current_declaration >= _NUM_DECLARATIONS - 1:
        #     return [1]
        actions = [0, 1] # 0: å®£è¨€, 1: ãƒãƒ£ãƒ¬ãƒ³ã‚¸
        return actions
    
    def chance_outcomes(self):
        # å±±æœ­ã«æ®‹ã£ãŸã‚«ãƒ¼ãƒ‰ã®ã‚«ã‚¦ãƒ³ãƒˆ
        counts = {}
        for card in self.deck.cards:
            counts[card] = counts.get(card, 0) + 1
        total = len(self.deck.cards)
        return [(card, cnt/total) for card, cnt in counts.items()]

    def _apply_action(self, action):
        # Chanceãƒãƒ¼ãƒ‰ã«ç§»è¡Œã™ã‚‹å ´åˆ
        if self.current_player() == PlayerId.CHANCE:
            # question ã‚«ãƒ¼ãƒ‰ã‚’å¼•ã„ãŸå ´åˆ
            if self._calc_continue:
                drawn_card = action  # action ãŒã‚«ãƒ¼ãƒ‰å€¤
                self._cards[self.question_index] = drawn_card
                self.deck.cards.remove(drawn_card)
                self._used_cards.append(drawn_card)
                self._calc_continue = False
                self._expecting_draw = False
                if self.deck.cards == []:
                    self.deck.reset()
                    self._used_cards = []
                return
            # ãƒ‰ãƒ­ãƒ¼å‡¦ç†
            drawn_card = action  # action ãŒã‚«ãƒ¼ãƒ‰å€¤
            self._cards[self._cur_player] = drawn_card
            self.deck.cards.remove(drawn_card)  # å±±æœ­ã‹ã‚‰ã‚«ãƒ¼ãƒ‰ã‚’å‰Šé™¤
            if self.deck.cards == []:
                self.deck.reset()
                self._used_cards = []
            self._cur_player = (self._cur_player + 1) % _NUM_PLAYERS
            while not self._player_active[self._cur_player]:
                self._cards[self._cur_player] = 0
                self._cur_player = (self._cur_player + 1) % _NUM_PLAYERS
            # ãƒ•ãƒ©ã‚°ã‚¯ãƒªã‚¢ï¼†é€šå¸¸ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«æˆ»ã™
            if not None in self._cards:
                self._expecting_draw = False
            else:
                self._expecting_draw = True
            return

        if (action == 1 or self.current_declaration >= _NUM_DECLARATIONS - 1) or self._calc_continue:  # ãƒãƒ£ãƒ¬ãƒ³ã‚¸
            # print(f"Current Cards: {self._cards}")
            # print(f"Player {self._cur_player} challenges with declaration {self.current_declaration}.")
            if 103 in self._cards:
                question_index = self._cards.index(103)
                self._cards[question_index] = None
                self.question_index = question_index
                self._calc_continue = True
                self._expecting_draw = True
                return

            true_total = self.convert_card(self._cards, False, self.deck)

            # used_cardsã«ã‚«ãƒ¼ãƒ‰ã‚’è¿½åŠ 
            for i in range(_NUM_PLAYERS):
                if self._player_active[i] and i != self._cur_player:
                    # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªå ´åˆã¯ã‚«ãƒ¼ãƒ‰ã‚’è¿½åŠ è‡ªåˆ†ã®ã‚«ãƒ¼ãƒ‰ã¯è¦‹ãˆãªã„
                    if self._cards[i] in self._all_cards and i != self.question_index:
                        self._used_cards.append(self._cards[i])

            if self.current_declaration > true_total:
                loser = self.last_declarer
            else:
                loser = self._cur_player
            self._player_lives[loser] -= 1
            if self._player_lives[loser] <= 0:
                self._player_active[loser] = False
            self._is_terminal = sum(self._player_active) <= 1
            self.current_declaration = 0

            if self.is_shuffle_card:
                # SHUFFLEã‚«ãƒ¼ãƒ‰ã‚’å¼•ã„ãŸ => å±±æœ­ã‚’ãƒªã‚»ãƒƒãƒˆ
                self.deck.reset()
                self._used_cards = []
                self.is_shuffle_card = False
            self._cards = [None] * _NUM_PLAYERS  # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æ‰‹æœ­ã‚’Noneã«ã™ã‚‹
            self._expecting_draw = True
            self.question_index = None
            # used_cardsã«ã‚«ãƒ¼ãƒ‰ã‚’è¿½åŠ 
            # print(f"Used cards: {self._used_cards}")
            # print(f"Player {loser} loses a life!")
            # print(f"Player lives: {self._player_lives}")
        else:
            # print(f"Player {self._cur_player} declares {self.current_declaration+1}.")
            self.current_declaration = self.current_declaration + 1
            self.last_declarer = self._cur_player

        self._cur_player = (self._cur_player + 1) % _NUM_PLAYERS
        while not self._player_active[self._cur_player]:
            self._cur_player = (self._cur_player + 1) % _NUM_PLAYERS

    def is_terminal(self):
        # if self._is_terminal:
        #     print(f"Game over! Player {self._cur_player} wins!")
        return self._is_terminal

    def returns(self):
        survive = sum(self._player_active)
        points = _NUM_PLAYERS - survive
        reward_ls = np.array([points/survive if self._player_active[i] else -1 for i in range(_NUM_PLAYERS)])
        return reward_ls / max(reward_ls)  # æ­£è¦åŒ–
    
    def information_state_string(self, player=None):
        if player is None:
            player = self._cur_player

        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æƒ…å ±çŠ¶æ…‹ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        # å®£è¨€å€¤ 1 + ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ©ã‚¤ãƒ• _NUM_PLAYERS + ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æ‰‹æœ­ (_NUM_PLAYERS - 1) * 4 + remaining_cards 15
        # å®£è¨€å€¤ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        declaration_str = str(self.current_declaration)
        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ©ã‚¤ãƒ•ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        lives_str = ",".join([str(self._player_lives[(i+player) % _NUM_PLAYERS]) for i in range(_NUM_PLAYERS)])
        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æ‰‹æœ­ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        hand_str = ",".join([str(self._cards[(i+player+1) % _NUM_PLAYERS]) for i in range(_NUM_PLAYERS-1)])
        # æ®‹ã‚Šã®ã‚«ãƒ¼ãƒ‰ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        cards_kind = [-10, -5, 0, 1, 2, 3, 4, 5, 10, 15, 20, 100, 101, 102, 103]
        visible_cards = self._all_cards.copy()
        for card in self._used_cards:
            if card in visible_cards:
                visible_cards.remove(card)
        for card in [self._cards[i] for i in range(len(self._cards)) if i != player and self._player_active[i]]:
            if card in visible_cards:
                visible_cards.remove(card)
        remaining_cards_str = ",".join([str(np.sum([1 for card in visible_cards if card == cards_kind[i]])) for i in range(15)])
        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æƒ…å ±çŠ¶æ…‹ã‚’æ–‡å­—åˆ—ã«çµåˆ
        info_state_str = f"{declaration_str},{lives_str},{hand_str},{remaining_cards_str}"
        return info_state_str

    def information_state_tensor(self, player=None):
        if player is None:
            player = self._cur_player
        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æƒ…å ±çŠ¶æ…‹ã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
        # å®£è¨€å€¤ 1 + ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ©ã‚¤ãƒ• _NUM_PLAYERS + ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æ‰‹æœ­ (_NUM_PLAYERS - 1) * 4 + remaining_cards 15 + current_estimate + the difference between the current estimate and the current declaration
        tensor = np.zeros(1 + _NUM_PLAYERS + (_NUM_PLAYERS - 1)*4 + 15 + 1 + 1, dtype=np.float32)

        # ç¾åœ¨ã®å®£è¨€å€¤ã‚’å…¥ã‚Œã‚‹
        tensor[0] = self.current_declaration

        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ©ã‚¤ãƒ•ã‚’å…¥ã‚Œã‚‹
        for i in range(_NUM_PLAYERS):
            tensor[i + 1] = self._player_lives[(i+player) % _NUM_PLAYERS]

        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æ‰‹æœ­ã‚’å…¥ã‚Œã‚‹
        for i in range(_NUM_PLAYERS-1):
            # (value,is_max,is_double,is_question)ã®å½¢ã§å„ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼å…¥ã‚Œã¦ã„ã
            if self._cards[(i+player+1) % _NUM_PLAYERS] == 102:
                tensor[1 + _NUM_PLAYERS + i*4] = 0
                tensor[1 + _NUM_PLAYERS + i*4 + 1] = 1
                tensor[1 + _NUM_PLAYERS + i*4 + 2] = 0
                tensor[1 + _NUM_PLAYERS + i*4 + 3] = 0
            elif self._cards[(i+player+1) % _NUM_PLAYERS] == 100:
                tensor[1 + _NUM_PLAYERS + i*4] = 0
                tensor[1 + _NUM_PLAYERS + i*4 + 1] = 0
                tensor[1 + _NUM_PLAYERS + i*4 + 2] = 1
                tensor[1 + _NUM_PLAYERS + i*4 + 3] = 0
            elif self._cards[(i+player+1) % _NUM_PLAYERS] == 103:
                tensor[1 + _NUM_PLAYERS + i*4] = 0
                tensor[1 + _NUM_PLAYERS + i*4 + 1] = 0
                tensor[1 + _NUM_PLAYERS + i*4 + 2] = 0
                tensor[1 + _NUM_PLAYERS + i*4 + 3] = 1
            elif self._cards[(i+player+1) % _NUM_PLAYERS] == 101:
                tensor[1 + _NUM_PLAYERS + i*4] = 0
                tensor[1 + _NUM_PLAYERS + i*4 + 1] = 0
                tensor[1 + _NUM_PLAYERS + i*4 + 2] = 0
                tensor[1 + _NUM_PLAYERS + i*4 + 3] = 0
            else:
                tensor[1 + _NUM_PLAYERS + i*4] = self._cards[(i+player+1) % _NUM_PLAYERS]
                tensor[1 + _NUM_PLAYERS + i*4 + 1] = 0
                tensor[1 + _NUM_PLAYERS + i*4 + 2] = 0
                tensor[1 + _NUM_PLAYERS + i*4 + 3] = 0

        cards_kind = [-10, -5, 0, 1, 2, 3, 4, 5, 10, 15, 20, 100, 101, 102, 103]

        # æ®‹ã‚Šã®ã‚«ãƒ¼ãƒ‰ã‚’å…¥ã‚Œã‚‹
        visible_cards = self._all_cards.copy()
        for card in self._used_cards:
            if card in visible_cards:
                visible_cards.remove(card)
        for card in [self._cards[i] for i in range(len(self._cards)) if i != player and self._player_active[i]]:
            if card in visible_cards:
                visible_cards.remove(card)

        # æ®‹ã‚Šã®ã‚«ãƒ¼ãƒ‰ã‚’å…¥ã‚Œã‚‹
        for i in range(15):
            tensor[1 + _NUM_PLAYERS + (_NUM_PLAYERS - 1)*4 + i] = np.sum([1 for card in visible_cards if card == cards_kind[i]])

        # ç¾åœ¨ã®ç›¸æ‰‹ã®ã‚«ãƒ¼ãƒ‰ã®åˆè¨ˆå€¤ã‚’å…¥ã‚Œã‚‹
        current_estimate = 0
        max_card = -100
        max_flag = False
        double_flag = False
        for i in range(_NUM_PLAYERS):
            if self._cards[i] is None:
                continue
            elif (self._player_active[i]) and (i != player) and (self._cards[i] < 100):
                current_estimate += self._cards[i]
                if self._cards[i] > max_card:
                    max_card = self._cards[i]
            elif self._player_active[i] and (i != player) and (self._cards[i] == 100):
                current_estimate += 0
                double_flag = True
            elif self._player_active[i] and (i != player) and (self._cards[i] == 102):
                current_estimate += 0
                max_flag = True
        
        if max_flag:
            current_estimate -= max_card

        if double_flag:
            current_estimate *= 2

        tensor[1 + _NUM_PLAYERS + (_NUM_PLAYERS - 1)*4 + 15] = current_estimate
        # ç¾åœ¨ã®å®£è¨€å€¤ã¨ã®å·®ã‚’å…¥ã‚Œã‚‹
        tensor[1 + _NUM_PLAYERS + (_NUM_PLAYERS - 1)*4 + 16] = current_estimate - self.current_declaration

        return tensor

    def __str__(self):
        return f"Cards: {self._cards}\nCurrent declaration: {self.current_declaration}\nLives: {self._player_lives}\nActive players: {self._player_active}"

class CoyoteObserver:
    def __init__(self, params):
        self.params = params or {}

    def set_from(self, state: CoyoteState, player: int):
        visible = [str(card) if i != player else "?" for i, card in enumerate(state._cards)]
        self.obs_str = f"Visible cards: {visible}\nDeclaration: {state.current_declaration}"

    def string_from(self, state: CoyoteState, player: int):
        self.set_from(state, player)
        return self.obs_str


class CoyoteGame(pyspiel.Game):
    def __init__(self, params=None):
        super().__init__(_GAME_TYPE, _GAME_INFO, params or {})
    
    def new_initial_state(self):
        return CoyoteState(self)
    
    def make_py_observer(self, iig_obs_type=None, params=None):
        return CoyoteObserver(params)


# ç™»éŒ²
pyspiel.register_game(_GAME_TYPE, CoyoteGame)


if __name__ == "__main__":

    # cfrã§æ•°ç†ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
    # Check for TensorFlow GPU access

    game = CoyoteGame() # ã‚²ãƒ¼ãƒ ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ

    dirname = os.path.dirname(__file__)

    # while True:
    # ä¿å­˜å…ˆãƒ‘ã‚¹
    ckpt_path = os.path.join(dirname, "checkpoints", "deep_cfr.ckpt")
    # for _ in tqdm.tqdm(range(100000)):
    #     # ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
    with tf.Session() as sess:

        # DeepCFRSolver æ§‹ç¯‰
        solver = deep_cfr.DeepCFRSolver(
            game=game,
            session=sess,
            policy_network_layers=[64, 64],
            advantage_network_layers=[64, 64],
            num_iterations=5,
            num_traversals=100,
            learning_rate=1e-4,
            batch_size_advantage=128,
            batch_size_strategy=128,
            memory_capacity=1e6
        )

        # å¤‰æ•°åˆæœŸåŒ–
        sess.run(tf.global_variables_initializer())

        # saver æº–å‚™ï¼ˆsolverå¾Œã˜ã‚ƒãªã„ã¨å¤‰æ•°ãŒæ§‹ç¯‰ã•ã‚Œã¦ãªã„ï¼‰
        saver = tf.train.Saver()

        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒå­˜åœ¨ã™ã‚Œã°å¾©å…ƒ
        if os.path.exists(ckpt_path + ".index"):
            print("âœ… Checkpoint found. Restoring model...")
            saver.restore(sess, ckpt_path)
            print("âœ… Model restored!")
            # epochã®å¾©å…ƒ
            with open(os.path.join(dirname, "epoch.txt"), "r") as f:
                epoch = int(f.read())
            print("Epoch:", epoch)

            # Advantage lossesã®å¾©å…ƒ
            with open(os.path.join(dirname, "advantage_losses.npy"), "rb") as f:
                advantage_losses_history = np.load(f)
            # print("Advantage losses:", advantage_losses_history[-1])

            # Policy lossã®å¾©å…ƒ
            with open(os.path.join(dirname, "policy_loss.npy"), "rb") as f:
                policy_loss_history = np.load(f)
            print("Policy loss:", policy_loss_history[-1])
        
        else:

            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ–°è¦ä½œæˆ
            policy_loss_history = np.array([])
            advantage_losses_history = None


        # å­¦ç¿’ï¼ˆè¿½åŠ è¨“ç·´ï¼‰
        print("ğŸš€ Starting DeepCFR training...")
        # é€²æ—è¡¨ç¤º
        for i in tqdm.tqdm(range(100000)):
            # 1ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å­¦ç¿’
            _, advantage_losses, policy_loss = solver.solve()

            # ä¿å­˜
            saver.save(sess, ckpt_path)
            print("ğŸ’¾ Model saved to:", ckpt_path)

            with open(os.path.join(dirname, "epoch.txt"), "w") as f:
                f.write(str(i + 1))

            advantage_losses_ls = np.array([advantage_losses[i] for i in range(_NUM_PLAYERS)]).reshape(-1, _NUM_PLAYERS)

            if advantage_losses_history is None:
                advantage_losses_history = advantage_losses_ls
            else:
                advantage_losses_history = np.vstack((advantage_losses_history, advantage_losses_ls))

            # historyã«è¿½åŠ 
            # advantage_losses_history = np.append(advantage_losses_history, advantage_losses)
            policy_loss_history = np.append(policy_loss_history, policy_loss)

            # ä¿å­˜
            np.save(os.path.join(dirname, "advantage_losses.npy"), advantage_losses_history)
            np.save(os.path.join(dirname, "policy_loss.npy"), policy_loss_history)

            # plot loss
            for i in range(_NUM_PLAYERS):
                plt.plot(advantage_losses_history[:,i], label=f"Player_{i}_Advantage_Loss")
            plt.xlabel("Iteration")
            plt.ylabel("Loss")
            plt.yscale('log')
            plt.title("DeepCFR Advantage Loss")
            plt.legend()
            plt.savefig(os.path.join(dirname, "advantage_loss.png"))
            plt.close()
            
            # plot policy loss
            plt.plot(policy_loss_history, label="Policy Loss")
            plt.xlabel("Iteration")
            plt.yscale('log')
            plt.ylabel("Loss")
            plt.title("DeepCFR Loss")
            plt.legend()
            plt.savefig(os.path.join(dirname, "policy_loss.png"))
            plt.close()

        print("âœ… Training complete!")